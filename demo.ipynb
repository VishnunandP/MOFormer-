{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the packages\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# load the runner \n",
    "from finetune_transformer import FineTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'epochs': 1, 'eval_every_n_epochs': 1, 'fine_tune_from': './training_results/pretraining', 'trained_with': 'CGCNN', 'log_every_n_steps': 50, 'gpu': 'cuda:0', 'vocab_path': 'tokenizer/vocab_full.txt', 'cuda': True, 'num_workers': 0, 'task': 'regression', 'optim': {'optimizer': 'Adam', 'init_lr': 5e-05, 'weight_decay': '1e-6'}, 'dataloader': {'valid_ratio': 0.15, 'test_ratio': 0.15, 'use_ratio': 1, 'randomSeed': 0}, 'dataset': {'data_name': 'QMOF', 'dataPath': './benchmark_datasets/QMOF/mofid/QMOF_small_mofid.csv'}, 'Transformer': {'ntoken': 4021, 'd_model': 512, 'nhead': 8, 'd_hid': 512, 'nlayers': 6, 'dropout': 0.1}}\n",
      "Running on: cpu\n",
      "The random seed is:  0\n",
      "Train size: 5226, Validation size: 1119, Test size: 1119\n",
      "Pre-trained weights not found. Training from scratch.\n",
      "Epoch: 1, Batch: 0, Loss: 0.9366955757141113\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "config = yaml.load(open(\"config_ft_transformer.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "config['dataloader']['randomSeed'] = 0\n",
    "print(config)\n",
    "\n",
    "if 'hMOF' in config['dataset']['data_name']:\n",
    "    task_name = config['dataset']['data_name']\n",
    "    pressure = config['dataset']['data_name'].split('_')[-1]\n",
    "if 'QMOF' in config['dataset']['data_name']:\n",
    "    task_name = 'QMOF'\n",
    "\n",
    "# ftf: finetuning from\n",
    "# ptw: pre-trained with\n",
    "if config['fine_tune_from'] == 'scratch':\n",
    "    ftf = 'scratch'\n",
    "    ptw = 'scratch'\n",
    "else:\n",
    "    ftf = config['fine_tune_from'].split('/')[-1]\n",
    "    ptw = config['trained_with']\n",
    "\n",
    "seed = config['dataloader']['randomSeed']\n",
    "\n",
    "log_dir = os.path.join(\n",
    "    'training_results/finetuning/Transformer',\n",
    "    'Trans_{}_{}_{}'.format(ptw,task_name,seed)\n",
    ")\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# run the training on dataset\n",
    "fine_tune = FineTune(config, log_dir)\n",
    "fine_tune.train()\n",
    "loss, metric = fine_tune.test()\n",
    "\n",
    "# save the training results\n",
    "fn = 'Trans_{}_{}_{}.csv'.format(ptw,task_name,seed)\n",
    "print(fn)\n",
    "df = pd.DataFrame([[loss, metric.item()]])\n",
    "df.to_csv(\n",
    "    os.path.join(log_dir, fn),\n",
    "    mode='a', index=False, header=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f500d17eed922cc41d241365cbecf175668272b49f129dd36f114ee91dac5ea7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

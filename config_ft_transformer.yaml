batch_size: 64
epochs: 200
eval_every_n_epochs: 1
fine_tune_from: ./training_results/pretraining
trained_with: 'CGCNN'
log_every_n_steps: 50
gpu: cuda:0
vocab_path: 'tokenizer/vocab_full.txt'
cuda: True
num_workers: 0
task: 'regression'

optim:
  optimizer: Adam
  init_lr: 0.00005
  weight_decay: 1e-6

dataloader:
  valid_ratio: 0.15
  test_ratio: 0.15
  use_ratio: 1
  randomSeed: 1

dataset:
  data_name: 'PS_Usable_Hydrogen_Storage'
  dataPath: './path_to_dataset/PS_Usable_Hydrogen_Storgae_Capaciti_GCMC.xlsx' # Adjust this path to match the exact location in the repo
  feature_columns: ['column1', 'column2', 'column3']  # Replace with actual feature column names
  target_column: 'target_column_name'                # Replace with actual target column name

Transformer:
  ntoken: 4021        # Adjust if using a different tokenizer or input size
  d_model: 512
  nhead: 8
  d_hid: 512
  nlayers: 6
  dropout: 0.1

